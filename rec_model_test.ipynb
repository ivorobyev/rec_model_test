{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#получаем набор данных\n",
    "products_df = pd.read_csv('products.csv')\n",
    "transactions_df =  pd.read_csv('transactions.csv')\n",
    "\n",
    "#вычисляем процент каждого товара от общего числа, купленных каждым юзером\n",
    "user_product = transactions_df.groupby(['user_id', 'product_id'])['product_id'].count()\n",
    "user = transactions_df.groupby(['user_id'])['product_id'].count()\n",
    "g = pd.DataFrame(user_product.div(user, level='user_id')).add_suffix('_count').reset_index()\n",
    "\n",
    "#присваиваем каждому юзеру и товару порядковые номера\n",
    "le = LabelEncoder()\n",
    "g['user_id_num'] = le.fit_transform(g['user_id'])\n",
    "g['product_id_num'] = le.fit_transform(g['product_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g[['user_id', 'user_id_num']].drop_duplicates().to_csv('users_meta.csv')\n",
    "g[['product_id', 'product_id_num']].drop_duplicates().to_csv('products_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, concatenate, Dropout, Dense, dot, BatchNormalization, Add\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot\n",
    "\n",
    "#строим модель NCF (neural collaborative filtering) paper: https://arxiv.org/pdf/1708.05031.pdf\n",
    "\n",
    "num_users = len(g.user_id_num.unique())\n",
    "num_product = len(g.product_id_num.unique())\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "product_input = Input(shape=[1],name='product-input')\n",
    "user_input = Input(shape=[1], name='user-input')\n",
    "\n",
    "product_embedding_mlp = Embedding(num_product + 1, latent_dim, name='product-embedding-mlp')(product_input)\n",
    "product_vec_mlp = Flatten(name='flatten-product-mlp')(product_embedding_mlp)\n",
    "\n",
    "user_embedding_mlp = Embedding(num_users + 1, latent_dim, name='user-embedding-mlp')(user_input)\n",
    "user_vec_mlp = Flatten(name='flatten-user-mlp')(user_embedding_mlp)\n",
    "\n",
    "product_embedding_mf = Embedding(num_product + 1, latent_dim, name='product-embedding-mf')(product_input)\n",
    "product_vec_mf = Flatten(name='flatten-product-mf')(product_embedding_mf)\n",
    "\n",
    "user_embedding_mf = Embedding(num_users + 1, latent_dim, name='user-embedding-mf')(user_input)\n",
    "user_vec_mf = Flatten(name='flatten-user-mf')(user_embedding_mf)\n",
    "\n",
    "concat = concatenate([product_vec_mlp, user_vec_mlp], name='concat')\n",
    "concat_dropout = Dropout(0.2)(concat)\n",
    "fc_1 = Dense(100, name='fc-1', activation='relu')(concat_dropout)\n",
    "fc_1_bn = BatchNormalization(name='batch-norm-1')(fc_1)\n",
    "fc_1_dropout = Dropout(0.2)(fc_1_bn)\n",
    "fc_2 = Dense(50, name='fc-2', activation='relu')(fc_1_dropout)\n",
    "fc_2_bn = BatchNormalization(name='batch-norm-2')(fc_2)\n",
    "fc_2_dropout = Dropout(0.2)(fc_2_bn)\n",
    "\n",
    "pred_mlp = Dense(10, name='pred-mlp', activation='relu')(fc_2_dropout)\n",
    "pred_mf = dot([product_vec_mf, user_vec_mf], normalize = False, axes = -1, name='pred-mf')\n",
    "combine_mlp_mf = concatenate([pred_mf, pred_mlp], name='combine-mlp-mf')\n",
    "\n",
    "# Final prediction\n",
    "result = Dense(1, name='result', activation='relu')(combine_mlp_mf)\n",
    "\n",
    "model = Model([user_input, product_input], result)\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mean_absolute_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train, X_test = train_test_split(g,test_size=0.4,random_state=42)\n",
    "\n",
    "history = model.fit([X_train.user_id_num, X_train.product_id_num], X_train.product_id_count, epochs=1)\n",
    "\n",
    "y_hat = np.round(model.predict([X_test.user_id_num, X_test.product_id_num]), decimals=2)\n",
    "y_true = X_test.product_id_count\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ncf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "model = load_model('ncf.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
